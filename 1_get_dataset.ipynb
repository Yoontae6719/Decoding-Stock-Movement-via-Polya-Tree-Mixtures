{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04d5913a-44bf-4946-8dab-d854da1b2474",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Date     Y   Y_2   Y_3   Y_4   Y_5       SMA_2       EMA_2     ROC_2  \\\n",
      "0 2020-03-26  SELL   BUY   BUY   BUY   BUY  294.960007  297.221886  0.104095   \n",
      "1 2020-03-27   BUY  SELL  SELL  SELL  SELL  300.845001  296.907295  0.041301   \n",
      "2 2020-03-30   BUY   BUY   BUY   BUY   BUY  306.440002  309.722435  0.036696   \n",
      "3 2020-03-31  SELL  SELL   BUY   BUY   BUY  316.255005  314.160815  0.066150   \n",
      "4 2020-04-01   BUY  SELL  SELL  SELL  SELL  304.824997  300.233598 -0.072312   \n",
      "\n",
      "        RSI_2  ...  CloseStd_26   Range_27  CloseStd_27   Range_28  \\\n",
      "0  100.000000  ...    20.419658  17.487775    21.175643  17.217140   \n",
      "1   70.905846  ...    19.440730  17.729999    20.089591  17.323569   \n",
      "2   70.293797  ...    18.435967  18.205184    19.212699  17.929999   \n",
      "3  100.000000  ...    18.047460  18.483702    18.262901  17.938570   \n",
      "4    1.070205  ...    17.580483  18.947777    17.786678  18.648927   \n",
      "\n",
      "   CloseStd_28   Range_29  CloseStd_29   Range_30  CloseStd_30  Stock  \n",
      "0    21.566385  16.746549    21.694580  16.517665    21.828505   BIIB  \n",
      "1    20.862351  17.067929    21.274301  16.617998    21.425392   BIIB  \n",
      "2    19.827545  17.530688    20.569068  17.276665    20.966701   BIIB  \n",
      "3    18.994445  17.682068    19.578269  17.304331    20.290805   BIIB  \n",
      "4    18.023623  18.116895    18.770400  17.862998    19.371189   BIIB  \n",
      "\n",
      "[5 rows x 444 columns]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import yfinance as yf\n",
    "import warnings\n",
    "import pandas as pd\n",
    "warnings.simplefilter(action='ignore', category=pd.errors.PerformanceWarning)\n",
    "\n",
    "def ST_labels(data, delta):\n",
    "    \"\"\"\n",
    "    Calculate the stop-loss adjusted label.\n",
    "\n",
    "    Parameters:\n",
    "    - data: DataFrame containing historical asset prices.\n",
    "    - delta: Maximum tolerance level for stop-loss trading.\n",
    "\n",
    "    Returns:\n",
    "    - Index of rows where the label is 1 (BUY).\n",
    "    \"\"\"\n",
    "    return data[\n",
    "        (data[\"Close\"] / data[\"Close\"].shift(1) > 1) & \n",
    "        ((data[\"Low\"] / data[\"Close\"].shift(1) - 1) * 100 >= -delta)\n",
    "    ].index\n",
    "\n",
    "def moving_average(series: pd.Series, window: int) -> pd.Series:\n",
    "    return series.rolling(window).mean()\n",
    "\n",
    "def exponential_moving_average(series: pd.Series, window: int) -> pd.Series:\n",
    "    return series.ewm(span=window, adjust=False).mean()\n",
    "\n",
    "def rate_of_change(series: pd.Series, window: int) -> pd.Series:\n",
    "    shifted = series.shift(window)\n",
    "    return (series - shifted) / (shifted + 1e-9)\n",
    "\n",
    "def rsi(series: pd.Series, window: int) -> pd.Series:\n",
    "    diff = series.diff(1)\n",
    "    gain = diff.clip(lower=0)\n",
    "    loss = diff.clip(upper=0).abs()\n",
    "    avg_gain = gain.rolling(window).mean()\n",
    "    avg_loss = loss.rolling(window).mean()\n",
    "    rs = avg_gain / (avg_loss + 1e-9)\n",
    "    return 100 - (100 / (1 + rs))\n",
    "\n",
    "def macd_signal(series: pd.Series, short_window: int = 12, long_window: int = 26, signal_window: int = 9):\n",
    "    ema_short = exponential_moving_average(series, short_window)\n",
    "    ema_long = exponential_moving_average(series, long_window)\n",
    "    macd_line = ema_short - ema_long\n",
    "    signal_line = exponential_moving_average(macd_line, signal_window)\n",
    "    return macd_line, signal_line\n",
    "\n",
    "def stochastic_oscillator(high: pd.Series, low: pd.Series, close: pd.Series, window: int = 14):\n",
    "    highest_high = high.rolling(window).max()\n",
    "    lowest_low = low.rolling(window).min()\n",
    "    k = (close - lowest_low) / (highest_high - lowest_low + 1e-9) * 100\n",
    "    d = k.rolling(3).mean()\n",
    "    return k, d\n",
    "\n",
    "def williams_r(high: pd.Series, low: pd.Series, close: pd.Series, window: int = 14):\n",
    "    highest_high = high.rolling(window).max()\n",
    "    lowest_low = low.rolling(window).min()\n",
    "    wr = (highest_high - close) / (highest_high - lowest_low + 1e-9) * -100\n",
    "    return wr\n",
    "\n",
    "def bollinger_bands(series: pd.Series, window: int = 20, num_std: float = 2.0):\n",
    "    m_avg = series.rolling(window).mean()\n",
    "    m_std = series.rolling(window).std(ddof=0)\n",
    "    upper_band = m_avg + num_std * m_std\n",
    "    lower_band = m_avg - num_std * m_std\n",
    "    return m_avg, upper_band, lower_band\n",
    "\n",
    "def cci(high: pd.Series, low: pd.Series, close: pd.Series, window: int = 20):\n",
    "    typical_price = (high + low + close) / 3\n",
    "    ma = typical_price.rolling(window).mean()\n",
    "    md = (typical_price - ma).rolling(window).apply(lambda x: np.mean(np.abs(x)))\n",
    "    cci_val = (typical_price - ma) / (md * 0.015 + 1e-9)\n",
    "    return cci_val\n",
    "\n",
    "def create_features_and_labels(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.sort_values('Date').reset_index(drop=True)\n",
    "\n",
    "    features_df = df.copy()\n",
    "\n",
    "    features_df['NextClose'] = features_df['Close'].shift(-1)\n",
    "    features_df['Y'] = np.where(features_df['NextClose'] > features_df['Close'], 'BUY', 'SELL')\n",
    "    features_df.dropna(subset=['NextClose'], inplace=True)\n",
    "\n",
    "    for delta in [2, 3, 4, 5]:\n",
    "        buy_index = ST_labels(features_df, delta)\n",
    "        features_df[f'Y_{delta}'] = np.where(features_df.index.isin(buy_index), 'BUY', 'SELL')\n",
    "\n",
    "    period_list = list(range(2, 31))\n",
    "    technical_features = []\n",
    "\n",
    "    for w in period_list:\n",
    "        col_sma = f'SMA_{w}'\n",
    "        features_df[col_sma] = moving_average(features_df['Close'], w)\n",
    "        technical_features.append(col_sma)\n",
    "\n",
    "        col_ema = f'EMA_{w}'\n",
    "        features_df[col_ema] = exponential_moving_average(features_df['Close'], w)\n",
    "        technical_features.append(col_ema)\n",
    "\n",
    "        col_roc = f'ROC_{w}'\n",
    "        features_df[col_roc] = rate_of_change(features_df['Close'], w)\n",
    "        technical_features.append(col_roc)\n",
    "\n",
    "        col_rsi = f'RSI_{w}'\n",
    "        features_df[col_rsi] = rsi(features_df['Close'], w)\n",
    "        technical_features.append(col_rsi)\n",
    "\n",
    "        col_wr = f'WR_{w}'\n",
    "        features_df[col_wr] = williams_r(features_df['High'], features_df['Low'], features_df['Close'], w)\n",
    "        technical_features.append(col_wr)\n",
    "\n",
    "        col_cci = f'CCI_{w}'\n",
    "        features_df[col_cci] = cci(features_df['High'], features_df['Low'], features_df['Close'], w)\n",
    "        technical_features.append(col_cci)\n",
    "\n",
    "        col_bb_mid = f'BBmid_{w}'\n",
    "        col_bb_up = f'BBup_{w}'\n",
    "        col_bb_dn = f'BBdn_{w}'\n",
    "        bb_mid, bb_up, bb_dn = bollinger_bands(features_df['Close'], w)\n",
    "        features_df[col_bb_mid] = bb_mid\n",
    "        features_df[col_bb_up] = bb_up\n",
    "        features_df[col_bb_dn] = bb_dn\n",
    "        technical_features += [col_bb_mid, col_bb_up, col_bb_dn]\n",
    "\n",
    "        col_sto_k = f'StoK_{w}'\n",
    "        col_sto_d = f'StoD_{w}'\n",
    "        sto_k, sto_d = stochastic_oscillator(features_df['High'], features_df['Low'], features_df['Close'], w)\n",
    "        features_df[col_sto_k] = sto_k\n",
    "        features_df[col_sto_d] = sto_d\n",
    "        technical_features += [col_sto_k, col_sto_d]\n",
    "\n",
    "    macd_line, signal_line = macd_signal(features_df['Close'], 12, 26, 9)\n",
    "    features_df['MACD'] = macd_line\n",
    "    features_df['MACD_Signal'] = signal_line\n",
    "    technical_features += ['MACD', 'MACD_Signal']\n",
    "\n",
    "    for w in period_list:\n",
    "        col_vol_sma = f'Volume_SMA_{w}'\n",
    "        features_df[col_vol_sma] = moving_average(features_df['Volume'], w)\n",
    "        technical_features.append(col_vol_sma)\n",
    "\n",
    "        col_vol_ema = f'Volume_EMA_{w}'\n",
    "        features_df[col_vol_ema] = exponential_moving_average(features_df['Volume'], w)\n",
    "        technical_features.append(col_vol_ema)\n",
    "\n",
    "    for w in period_list:\n",
    "        col_range = f'Range_{w}'\n",
    "        features_df[col_range] = (features_df['High'] - features_df['Low']).rolling(w).mean()\n",
    "        technical_features.append(col_range)\n",
    "\n",
    "        col_close_std = f'CloseStd_{w}'\n",
    "        features_df[col_close_std] = features_df['Close'].rolling(w).std()\n",
    "        technical_features.append(col_close_std)\n",
    "\n",
    "    features_df.dropna(subset=technical_features, inplace=True)\n",
    "\n",
    "    label_cols = ['Y', 'Y_2', 'Y_3', 'Y_4', 'Y_5']\n",
    "    result_df = features_df[['Date'] + label_cols].join(\n",
    "        features_df[technical_features]\n",
    "    )\n",
    "    return result_df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    start_date = \"2020-01-01\"\n",
    "    end_date = \"2025-01-31\"\n",
    "\n",
    "    tickers = [\n",
    "        'BIIB', 'BA', 'AXP', 'SLB', 'COP', 'AVGO', 'TMO', 'NEE', 'NKE', 'MO',\n",
    "        'WBA', 'QCOM', 'COST', 'ACN', 'CVS', 'T', 'CVX', 'HD', 'DUK', 'CL',\n",
    "        'MMM', 'CSCO', 'BAC', 'LOW', 'BLK', 'MDLZ', 'PM', 'UNH', 'VZ', 'CAT',\n",
    "        'NVDA', 'FDX', 'RTX', 'AIG', 'TMUS', 'INTC', 'PEP', 'TGT', 'GD', 'GS',\n",
    "        'MDT', 'IBM', 'DIS', 'ORCL', 'COF', 'MSFT', 'KO', 'BKNG', 'V', 'LLY',\n",
    "        'ADBE', 'AMZN', 'SBUX', 'BMY', 'MRK', 'XOM', 'F', 'JNJ', 'USB', 'AMT',\n",
    "        'EXC', 'AAPL', 'SPG', 'TXN', 'PFE', 'PG', 'LMT', 'MCD', 'NFLX', 'UNP',\n",
    "        'HON', 'C', 'GOOG', 'AMGN', 'JPM', 'MA', 'CMCSA', 'ABT', 'SO',\n",
    "        'GILD', 'MET', 'MS', 'EMR', 'UPS', 'CRM', 'DHR', 'GOOGL', 'GE', 'WFC',\n",
    "        'WMT'\n",
    "    ]\n",
    "\n",
    "    all_results = []\n",
    "\n",
    "    for ticker in tickers:\n",
    "        try:\n",
    "            df = yf.download(\n",
    "                ticker,\n",
    "                start=start_date,\n",
    "                end=end_date,\n",
    "                group_by='column'\n",
    "            )\n",
    "\n",
    "            # MultiIndex인 경우 컬럼명 재설정\n",
    "            if isinstance(df.columns, pd.MultiIndex):\n",
    "                df.columns = ['_'.join(col).strip() for col in df.columns.values]\n",
    "\n",
    "            # 불러온 DataFrame에 필요한 컬럼명 매핑\n",
    "            possible_cols = list(df.columns)\n",
    "            rename_dict = {}\n",
    "            for col in ['Open','High','Low','Close','Volume']:\n",
    "                alt_name = col + '_' + ticker\n",
    "                if alt_name in possible_cols:\n",
    "                    rename_dict[alt_name] = col\n",
    "\n",
    "            df.rename(columns=rename_dict, inplace=True)\n",
    "\n",
    "            required_cols = {'Open','High','Low','Close','Volume'}\n",
    "            if not required_cols.issubset(df.columns):\n",
    "                continue\n",
    "\n",
    "            df.reset_index(inplace=True)\n",
    "            result_df = create_features_and_labels(df)\n",
    "            result_df['Stock'] = ticker\n",
    "            all_results.append(result_df)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            continue\n",
    "\n",
    "    if all_results:\n",
    "        final_df = pd.concat(all_results, axis=0).reset_index(drop=True)\n",
    "        print(final_df.head())\n",
    "    else:\n",
    "        print(\"There are No data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47d3ca3a-e42c-4538-b0a0-b8fe7377a8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv(\"./dataset/SNP.csv\", index =False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9deefc3a-10df-4002-8c25-dd318762599f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = final_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61670239-b8d6-40b9-a3ce-6fcfb83fd66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw[(df_raw['Date'] >= '2020-01-01') & (df_raw['Date'] <= '2022-12-31')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a5e7c4-48ec-4198-96ca-476d492acea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw[(df_raw['Date'] >= '2024-01-01')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79abc8e8-50af-4fb8-9ff3-30034687dffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw.columns[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0063a0a1-39d1-4cd6-a091-1942c6039be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw[['Y', 'Y_2', 'Y_3', 'Y_4']] = df_raw[['Y', 'Y_2', 'Y_3', 'Y_4']].apply(lambda x: x.map({'SELL': 0, 'BUY': 1}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c92977-8d64-4d7b-90e4-85c082e74a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72173dd9-7611-40b2-ae10-657f4f94923c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
